{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32a6ac62",
   "metadata": {},
   "source": [
    "### 1. Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d33625b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk import word_tokenize, pos_tag, stem\n",
    "from autocorrect import Speller\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91f421a",
   "metadata": {},
   "source": [
    "### 2. Load the text corpus to a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6e18532",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = open(\"/Users/kaylanguyen/Documents/TheNLPWorkshop/Activities/file.txt\", 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a916a119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The reader of this course should have a basic knowledge of the Python programming lenguage.\\nHe/she must have knowldge of data types in Python.He should be able to write functions,\\n and also have the ability to import and use libraries and packages in Python. Familiarity\\n with basic linguistics and probability is assumed although not required to fully\\n complete this course.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117eb5ca",
   "metadata": {},
   "source": [
    "### 3. Apply the tokenization process to the text corpus and print the first 20 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed67d67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_tokens(sentence):\n",
    "#     words = word_tokenize(sentence)\n",
    "#     return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fa782fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'reader', 'of', 'this', 'course', 'should', 'have', 'a', 'basic', 'knowledge', 'of', 'the', 'Python', 'programming', 'lenguage', '.', 'He/she', 'must', 'have', 'knowldge']\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(sentence)\n",
    "print(words[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d461335",
   "metadata": {},
   "source": [
    "### 4. Apply spelling correction on each token and print the initial 20 corrected tokens as well as the corrected text corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "857358de",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell = Speller(lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4bf10cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3a53ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def correct_spelling(tokens):\n",
    "#     sentence_corrected = ' '.join([spell(word) for word in tokens])\n",
    "#     return sentence_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ad92922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_sentence(words):\n",
    "    corrected_sentence = \"\"\n",
    "    corrected_word_list = []\n",
    "    for wd in words:\n",
    "        if wd not in string.punctuation:\n",
    "            wd_c = spell(wd)\n",
    "            if wd_c != wd:\n",
    "                print(wd+\" has been corrected to: \"+wd_c)\n",
    "                corrected_sentence = corrected_sentence+\" \"+wd_c\n",
    "                corrected_word_list.append(wd_c)\n",
    "            else:\n",
    "                corrected_sentence = corrected_sentence+\" \"+wd\n",
    "                corrected_word_list.append(wd)\n",
    "        else:\n",
    "            corrected_sentence = corrected_sentence + wd\n",
    "            corrected_word_list.append(wd)\n",
    "    return corrected_sentence, corrected_word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2aeb5ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenguage has been corrected to: language\n",
      "knowldge has been corrected to: knowledge\n"
     ]
    }
   ],
   "source": [
    "corrected_sentence, corrected_word_list = correct_sentence(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b4b756c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d20772eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenguage has been corrected to: language\n",
      "knowldge has been corrected to: knowledge\n",
      "(' The reader of this course should have a basic knowledge of the Python programming language. He/she must have knowledge of data types in Python.He should be able to write functions, and also have the ability to import and use libraries and packages in Python. Familiarity with basic linguistics and probability is assumed although not required to fully complete this course.', ['The', 'reader', 'of', 'this', 'course', 'should', 'have', 'a', 'basic', 'knowledge', 'of', 'the', 'Python', 'programming', 'language', '.', 'He/she', 'must', 'have', 'knowledge', 'of', 'data', 'types', 'in', 'Python.He', 'should', 'be', 'able', 'to', 'write', 'functions', ',', 'and', 'also', 'have', 'the', 'ability', 'to', 'import', 'and', 'use', 'libraries', 'and', 'packages', 'in', 'Python', '.', 'Familiarity', 'with', 'basic', 'linguistics', 'and', 'probability', 'is', 'assumed', 'although', 'not', 'required', 'to', 'fully', 'complete', 'this', 'course', '.'])\n"
     ]
    }
   ],
   "source": [
    "print(correct_sentence(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd993814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'reader', 'of', 'this', 'course', 'should', 'have', 'a', 'basic', 'knowledge', 'of', 'the', 'Python', 'programming', 'language', '.', 'He/she', 'must', 'have', 'knowledge']\n"
     ]
    }
   ],
   "source": [
    "print(corrected_word_list[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1933e724",
   "metadata": {},
   "source": [
    "### 5. Apply PoS tags to each of the corrected tokens and print them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e961c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_pos(words):\n",
    "#     return pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a73cda2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('reader', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('course', 'NN'),\n",
       " ('should', 'MD'),\n",
       " ('have', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('basic', 'JJ'),\n",
       " ('knowledge', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Python', 'NNP'),\n",
       " ('programming', 'NN'),\n",
       " ('language', 'NN'),\n",
       " ('.', '.'),\n",
       " ('He/she', 'NNP'),\n",
       " ('must', 'MD'),\n",
       " ('have', 'VB'),\n",
       " ('knowledge', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('data', 'NNS'),\n",
       " ('types', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('Python.He', 'NNP'),\n",
       " ('should', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('able', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('write', 'VB'),\n",
       " ('functions', 'NNS'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('also', 'RB'),\n",
       " ('have', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('ability', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('import', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('use', 'NN'),\n",
       " ('libraries', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('packages', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('Python', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Familiarity', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('basic', 'JJ'),\n",
       " ('linguistics', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('probability', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('assumed', 'VBN'),\n",
       " ('although', 'IN'),\n",
       " ('not', 'RB'),\n",
       " ('required', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('fully', 'RB'),\n",
       " ('complete', 'VB'),\n",
       " ('this', 'DT'),\n",
       " ('course', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag(corrected_word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf959ae",
   "metadata": {},
   "source": [
    "### 6. Remove stop words from the corrected token list and print the initial 20 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a9f4605",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eaf31339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_stop_words(sentence_words, stop_words):\n",
    "#     return ' '.join([word for word in sentence_words \\\n",
    "#                      if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d05d5e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removed_stopwords = [word for word in corrected_word_list \\\n",
    "#                       if word not in stop_words]\n",
    "# print(removed_stopwords[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e359799b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'reader', 'course', 'basic', 'knowledge', 'Python', 'programming', 'language', '.', 'He/she', 'must', 'knowledge', 'data', 'types', 'Python.He', 'able', 'write', 'functions', ',', 'also']\n"
     ]
    }
   ],
   "source": [
    "def remove_stop_words(sentence_words, stop_words):\n",
    "    return [word for word in sentence_words \\\n",
    "                     if word not in stop_words]\n",
    "print(remove_stop_words(corrected_word_list, stop_words)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6897a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'reader', 'course', 'basic', 'knowledge', 'Python', 'programming', 'language', '.', 'He/she', 'must', 'knowledge', 'data', 'types', 'Python.He', 'able', 'write', 'functions', ',', 'also']\n"
     ]
    }
   ],
   "source": [
    "def remove_stop_words_2(word_list):\n",
    "    corrected_word_list_without_stopwords = []\n",
    "    for wd in word_list:\n",
    "        if wd not in stop_words:\n",
    "            corrected_word_list_without_stopwords.append(wd)\n",
    "    return corrected_word_list_without_stopwords\n",
    "\n",
    "corrected_word_list_without_stopwords = remove_stop_words_2(corrected_word_list)\n",
    "print(corrected_word_list_without_stopwords[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713ac605",
   "metadata": {},
   "source": [
    "### 7. Apply stemming and lemmatization to the corrected token list and then print the initial 20 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8b215e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_stems(word, stemmer):\n",
    "#     return stemmer.stem(word)\n",
    "# porterStem = stem.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe2e9d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'reader', 'cours', 'basic', 'knowledg', 'python', 'program', 'languag', '.', 'he/sh', 'must', 'knowledg', 'data', 'type', 'python.h', 'abl', 'write', 'function', ',', 'also']\n"
     ]
    }
   ],
   "source": [
    "stemmer = stem.PorterStemmer()\n",
    "def get_stems(word_list):\n",
    "    corrected_word_list_without_stopwords_stemmed = []\n",
    "    for wd in word_list:\n",
    "        corrected_word_list_without_stopwords_stemmed.append(stemmer.stem(wd))\n",
    "    return corrected_word_list_without_stopwords_stemmed\n",
    "\n",
    "corrected_word_list_without_stopwords_stemmed = get_stems(corrected_word_list_without_stopwords)\n",
    "print(corrected_word_list_without_stopwords_stemmed[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8205369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_lemma(word):\n",
    "#     return lemmatizer.lemmatize(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86de32ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'reader', 'cours', 'basic', 'knowledg', 'python', 'program', 'languag', '.', 'he/sh', 'must', 'knowledg', 'data', 'type', 'python.h', 'abl', 'write', 'function', ',', 'also']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def get_lemma(word_list):\n",
    "    corrected_word_list_without_stopwords_lemmatized = []\n",
    "    for wd in word_list:\n",
    "        corrected_word_list_without_stopwords_lemmatized.append(lemmatizer.lemmatize(wd))\n",
    "    return corrected_word_list_without_stopwords_lemmatized\n",
    "corrected_word_list_without_stopwords_lemmatized =  get_lemma(corrected_word_list_without_stopwords_stemmed)\n",
    "print(corrected_word_list_without_stopwords_lemmatized[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c32ff8",
   "metadata": {},
   "source": [
    "### 8. Detect the sentence boundaries in the given text corpus and print the total number of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "469a8193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(text):\n",
    "    return sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "899da022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The reader of this course should have a basic knowledge of the Python programming language. He/she must have knowledge of data types in Python.He should be able to write functions, and also have the ability to import and use libraries and packages in Python. Familiarity with basic linguistics and probability is assumed although not required to fully complete this course.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "037c7472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' The reader of this course should have a basic knowledge of the Python programming language.',\n",
       " 'He/she must have knowledge of data types in Python.He should be able to write functions, and also have the ability to import and use libraries and packages in Python.',\n",
       " 'Familiarity with basic linguistics and probability is assumed although not required to fully complete this course.']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentences(corrected_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fdec5c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = sent_tokenize(corrected_sentence)\n",
    "len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4a299e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde2bdab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
